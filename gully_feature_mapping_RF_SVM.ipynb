{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNZoRotjl56KLsoQGf+eExQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Gully feature mapping using Machine Learning"],"metadata":{"id":"uKvwEe-Idl4q"}},{"cell_type":"markdown","source":["Author: @JaphethKimeu\n","\n","Requirements:\n","\n","*   Satellite image(s) - In this case, I am using Sentinel 2 imagery of Bari region, Puntland, Somalia. Remember to correct Atmospheric effects on your S2_L1C images.\n","*   Training and validation samples as shapefiles.\n","\n"],"metadata":{"id":"_Tftfa9ed-iG"}},{"cell_type":"markdown","source":["# Section 1 - Installing packages"],"metadata":{"id":"rmOLoUd0gOLK"}},{"cell_type":"code","source":["# import and mount google colab drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!ls /content/drive/"],"metadata":{"id":"sKiypDQ7gnIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import required packages\n","\n","from osgeo import gdal, ogr, gdal_array \n","import numpy as \n","import matplotlib.pyplot as plt \n","from sklearn.ensemble import RandomForestClassifier \n","from sklearn import svm\n","import pandas as pd \n","from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  \n","\n","import seaborn as sn\n","import os \n","import datetime\n","\n","# Tell GDAL to throw Python exceptions, and register all drivers\n","gdal.UseExceptions()\n","gdal.AllRegister()"],"metadata":{"id":"l_v7LATZg1B4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 2 - Input data\n","\n","*   Change the paths to mirror where you have saved your data\n","\n"],"metadata":{"id":"UlZ0z7EKhbjg"}},{"cell_type":"code","source":["# set number of trees (default = 1000), not required for svm\n","est = 1000\n","\n","# set number of cores to use\n","n_cores = -1 # all available cores\n","\n","# set path to image\n","img_RS = '/content/drive/MyDrive/gully_erosion/combined_2021jun1514.TIF'\n","\n","\n","# set path to training and validation shapefiles\n","training = '/content/drive/MyDrive/gully_erosion/training_2021jun1514.shp'\n","validation = '/content/drive/MyDrive/gully_erosion/validation_2021jun1514.shp'\n","\n","# define attribute name of your classes in the shapefile\n","attribute = 'class'\n","\n","\n","# set path to save image\n","classification_image = '/content/drive/MyDrive/gully_erosion/classified_jun1514.tif'\n","\n","# set path to save results\n","results_txt = '/content/drive/MyDrive/gully_erosion/results.txt'\n","# results_txt1 = '/content/drive/MyDrive/gully_erosion/results1.txt' # svm"],"metadata":{"id":"X8hjPv5lh_Xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load training data and show all shape attributes\n","shape_dataset = ogr.Open(training)\n","shape_layer = shape_dataset.GetLayer()\n","\n","# read the names of all attributes (fieldnames) in the shapefile\n","attributes = []\n","ldefn = shape_layer.GetLayerDefn()\n","for n in range(ldefn.GetFieldCount()):\n","    fdefn = ldefn.GetFieldDefn(n)\n","    attributes.append(fdefn.name)\n","    \n","# print the attributes\n","print('Available attributes in the shape file are: {}'.format(attributes))"],"metadata":{"id":"s5Hq865AjLjM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 3 - Data preparation"],"metadata":{"id":"3mTPpl6Njb2x"}},{"cell_type":"code","source":["# prepare results text file:\n","\n","print('Random Forest Classification', file=open(results_txt, \"a\"))\n","# print('SVM', file=open(results_txt1, \"a\"))\n","print('Processing: {}'.format(datetime.datetime.now()), file=open(results_txt, \"a\"))\n","print('-------------------------------------------------', file=open(results_txt, \"a\"))\n","print('PATHS:', file=open(results_txt, \"a\"))\n","print('Image: {}'.format(img_RS), file=open(results_txt, \"a\"))\n","print('Training shape: {}'.format(training) , file=open(results_txt, \"a\"))\n","print('Vaildation shape: {}'.format(validation) , file=open(results_txt, \"a\"))\n","print('      choosen attribute: {}'.format(attribute) , file=open(results_txt, \"a\"))\n","print('Classification image: {}'.format(classification_image) , file=open(results_txt, \"a\"))\n","print('Report text file: {}'.format(results_txt) , file=open(results_txt, \"a\"))\n","print('-------------------------------------------------', file=open(results_txt, \"a\"))"],"metadata":{"id":"e5YuYrlcjmJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load image data\n","\n","img_ds = gdal.Open(img_RS, gdal.GA_ReadOnly)\n","\n","img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n","               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n","for b in range(img.shape[2]):\n","    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()"],"metadata":{"id":"PEff7pTjjrQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read image size\n","row = img_ds.RasterYSize\n","col = img_ds.RasterXSize\n","band_number = img_ds.RasterCount\n","\n","# print image size and no. of bands\n","print('Image extent: {} x {} (row x col)'.format(row, col))\n","print('Number of Bands: {}'.format(band_number))\n","\n","\n","print('Image extent: {} x {} (row x col)'.format(row, col), file=open(results_txt, \"a\"))\n","print('Number of Bands: {}'.format(band_number), file=open(results_txt, \"a\"))\n","print('---------------------------------------', file=open(results_txt, \"a\"))\n","print('TRAINING', file=open(results_txt, \"a\"))\n","print('Number of Trees: {}'.format(est), file=open(results_txt, \"a\")) # change here for svm"],"metadata":{"id":"MeEgCJx2j8TH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load training data from shapefile\n","shape_dataset = ogr.Open(training)\n","shape_layer = shape_dataset.GetLayer()\n","\n","mem_drv = gdal.GetDriverByName('MEM')\n","mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n","mem_raster.SetProjection(img_ds.GetProjection())\n","mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n","mem_band = mem_raster.GetRasterBand(1)\n","mem_band.Fill(0)\n","mem_band.SetNoDataValue(0)\n","\n","att_ = 'ATTRIBUTE='+attribute\n","err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n","assert err == gdal.CE_None\n","\n","roi = mem_raster.ReadAsArray()"],"metadata":{"id":"AmDVqXi6kYo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display images\n","plt.subplot(121)\n","plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n","plt.title('RS image - first band')\n","\n","plt.subplot(122)\n","plt.imshow(roi, cmap=plt.cm.Spectral)\n","plt.title('Training Image')\n","\n","plt.show()\n","\n","# read number of training samples\n","n_samples = (roi > 0).sum()\n","print('{n} training samples'.format(n=n_samples))\n","print('{n} training samples'.format(n=n_samples), file=open(results_txt, \"a\"))\n","\n","# read no. of classes (this is a binary classification - 2 classes)\n","labels = np.unique(roi[roi > 0])\n","\n","print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n","print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels), file=open(results_txt, \"a\"))\n","\n","# Subset the image dataset with the training image = X\n","# Mask the classes on the training dataset = y\n","# These will have n_samples rows\n","X = img[roi > 0, :]\n","y = roi[roi > 0]\n","\n","print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n","print('Our y array is sized: {sz}'.format(sz=y.shape))"],"metadata":{"id":"QtmHLVvEkn-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 4 - Training the model"],"metadata":{"id":"VsLOKjvKlcNn"}},{"cell_type":"code","source":["# set rf parameters, # set verbose=2 to print every tree progression\n","rf = RandomForestClassifier(n_estimators=est, oob_score=True, verbose=1, n_jobs=n_cores)\n","\n","# support vector machines\n","# clf = svm.SVC(C=1, kernel='rbf', cache_size=800, random_state=None)\n","\n","X = np.nan_to_num(X)\n","rf2 = rf.fit(X, y)\n","# clf2 = clf.fit(X, y) #svm"],"metadata":{"id":"gUNxNXkalh55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check out the \"Out-of-Bag\" (OOB) prediction score: RF only\n","\n","print('--------------------------------', file=open(results_txt, \"a\"))\n","print('TRAINING and RF Model Diagnostics:', file=open(results_txt, \"a\"))\n","print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100))\n","print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100), file=open(results_txt, \"a\"))\n","\n","\n","# show the band importance: RF only\n","bands = range(1,img_ds.RasterCount+1)\n","\n","for b, imp in zip(bands, rf2.feature_importances_):\n","    print('Band {b} importance: {imp}'.format(b=b, imp=imp))\n","    print('Band {b} importance: {imp}'.format(b=b, imp=imp), file=open(results_txt, \"a\"))\n","\n","    \n","# Let's look at a crosstabulation to see the class confusion. \n","# To do so, we will import the Pandas library for some help:\n","# Setup a dataframe -- just like R\n","# Exception Handling because of possible Memory Error\n","\n","try:\n","    df = pd.DataFrame()\n","    df['truth'] = y\n","    df['predict'] = rf.predict(X)\n","    #df['predict'] = clf.predict(X) # svm\n","\n","except MemoryError:\n","    print('Crosstab not available ')\n","\n","else:\n","    # Cross-tabulate predictions\n","    print(pd.crosstab(df['truth'], df['predict'], margins=True))\n","    print(pd.crosstab(df['truth'], df['predict'], margins=True), file=open(results_txt, \"a\"))"],"metadata":{"id":"U9I7MOTQmM_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot confusion matrix\n","cm = confusion_matrix(y,rf.predict(X))\n","# cm = confusion_matrix(y,clf.predict(X)) # svm\n","plt.figure(figsize=(10,7))\n","sn.heatmap(cm, annot=True, fmt='g')\n","plt.xlabel('classes - predicted')\n","plt.ylabel('classes - truth')\n","plt.show()"],"metadata":{"id":"GASUgkgSmbBH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 5 - Prediction"],"metadata":{"id":"952ucddsmhBu"}},{"cell_type":"code","source":["# Predicting the rest of the image\n","\n","# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n","new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n","img_as_array = img[:, :, :np.int(img.shape[2])].reshape(new_shape)\n","\n","print('Reshaped from {o} to {n}'.format(o=img.shape, n=img_as_array.shape))\n","\n","img_as_array = np.nan_to_num(img_as_array)"],"metadata":{"id":"n8w3HdO6mprU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now predict for each pixel on the entire image, if not enough RAM, the dataset will be sliced\n","try:\n","    class_prediction = rf.predict(img_as_array)\n","    # class_prediction = rf.predict(img_as_array) # svm\n","except MemoryError:\n","    slices = int(round(len(img_as_array)/2))\n","\n","    test = True\n","    \n","    while test == True:\n","        try:\n","            class_preds = list()\n","            \n","            temp = rf.predict(img_as_array[0:slices+1,:])\n","           # temp = clf.predict(img_as_array[0:slices+1,:]) # svm\n","            class_preds.append(temp)\n","            \n","            for i in range(slices,len(img_as_array),slices):\n","                print('{} %, derzeit: {}'.format((i*100)/(len(img_as_array)), i))\n","                temp = rf.predict(img_as_array[i+1:i+(slices+1),:])\n","               # temp = clf.predict(img_as_array[i+1:i+(slices+1),:]) # svm                \n","                class_preds.append(temp)\n","            \n","        except MemoryError as error:\n","            slices = slices/2\n","            print('Not enought RAM, new slices = {}'.format(slices))\n","            \n","        else:\n","            test = False\n","else:\n","    print('Class prediction was successful without slicing!')"],"metadata":{"id":"J39HpYZbmsH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# concatenate all slices and re-shape it to the original extend\n","try:\n","    class_prediction = np.concatenate(class_preds,axis = 0)\n","except NameError:\n","    print('No slicing was necessary!')\n","    \n","class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n","print('Reshaped back to {}'.format(class_prediction.shape))"],"metadata":{"id":"e_9N3Tkpm7ha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 6 - Create a mask for classified image"],"metadata":{"id":"-sGKEivZnHxX"}},{"cell_type":"code","source":["# generate mask image from red band\n","mask = np.copy(img[:,:,0])\n","mask[mask > 0.0] = 1.0 # all actual pixels have a value of 1.0\n","\n","# plot mask\n","\n","plt.imshow(mask)"],"metadata":{"id":"VxnNMv2mnPLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot image mask\n","class_prediction.astype(np.float16)\n","class_prediction_ = class_prediction*mask\n","\n","plt.subplot(121)\n","plt.imshow(class_prediction, cmap=plt.cm.Spectral)\n","plt.title('classification unmasked')\n","\n","plt.subplot(122)\n","plt.imshow(class_prediction_, cmap=plt.cm.Spectral)\n","plt.title('classification masked')\n","\n","plt.show()"],"metadata":{"id":"xCVTeg2gnVtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save classified image to disk\n","cols = img.shape[1]\n","rows = img.shape[0]\n","\n","class_prediction_.astype(np.float16)\n","\n","driver = gdal.GetDriverByName(\"gtiff\")\n","outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_UInt16)\n","outdata.SetGeoTransform(img_ds.GetGeoTransform())##sets same geotransform as input\n","outdata.SetProjection(img_ds.GetProjection())##sets same projection as input\n","outdata.GetRasterBand(1).WriteArray(class_prediction_)\n","outdata.FlushCache() ##saves to disk!!\n","print('Image saved to: {}'.format(classification_image))"],"metadata":{"id":"YEn66aV8nj6u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 7 - Accuracy Assessment"],"metadata":{"id":"I3LO1M75n8MO"}},{"cell_type":"code","source":["# validation / accuracy assessment\n","\n","# preparing ttxt file\n","\n","print('------------------------------------', file=open(results_txt, \"a\"))\n","print('VALIDATION', file=open(results_txt, \"a\"))\n","\n","# laod training data from shape file\n","shape_dataset_v = ogr.Open(validation)\n","shape_layer_v = shape_dataset_v.GetLayer()\n","mem_drv_v = gdal.GetDriverByName('MEM')\n","mem_raster_v = mem_drv_v.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n","mem_raster_v.SetProjection(img_ds.GetProjection())\n","mem_raster_v.SetGeoTransform(img_ds.GetGeoTransform())\n","mem_band_v = mem_raster_v.GetRasterBand(1)\n","mem_band_v.Fill(0)\n","mem_band_v.SetNoDataValue(0)\n","\n","err_v = gdal.RasterizeLayer(mem_raster_v, [1], shape_layer_v, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n","assert err_v == gdal.CE_None\n","\n","roi_v = mem_raster_v.ReadAsArray()\n","\n","\n","\n","# vizualise\n","plt.subplot(221)\n","plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n","plt.title('RS_Image - first band')\n","\n","plt.subplot(222)\n","plt.imshow(class_prediction, cmap=plt.cm.Spectral)\n","plt.title('Classification result')\n","\n","\n","plt.subplot(223)\n","plt.imshow(roi, cmap=plt.cm.Spectral)\n","plt.title('Training Data')\n","\n","plt.subplot(224)\n","plt.imshow(roi_v, cmap=plt.cm.Spectral)\n","plt.title('Validation Data')\n","\n","plt.show()\n","\n","\n","# Find how many non-zero entries we have -- i.e. how many validation data samples?\n","n_val = (roi_v > 0).sum()\n","print('{n} validation pixels'.format(n=n_val))\n","print('{n} validation pixels'.format(n=n_val), file=open(results_txt, \"a\"))\n","\n","# What are our validation labels?\n","labels_v = np.unique(roi_v[roi_v > 0])\n","print('validation data include {n} classes: {classes}'.format(n=labels_v.size, classes=labels_v))\n","print('validation data include {n} classes: {classes}'.format(n=labels_v.size, classes=labels_v), file=open(results_txt, \"a\"))\n","# Subset the classification image with the validation image = X\n","# Mask the classes on the validation dataset = y\n","# These will have n_samples rows\n","X_v = class_prediction[roi_v > 0]\n","y_v = roi_v[roi_v > 0]\n","\n","print('Our X matrix is sized: {sz_v}'.format(sz_v=X_v.shape))\n","print('Our y array is sized: {sz_v}'.format(sz_v=y_v.shape))\n","\n","# Cross-tabulate predictions\n","# confusion matrix\n","convolution_mat = pd.crosstab(y_v, X_v, margins=True)\n","print(convolution_mat)\n","print(convolution_mat, file=open(results_txt, \"a\"))\n","# if you want to save the confusion matrix as a CSV file:\n","#savename = 'C:\\\\save\\\\to\\\\folder\\\\conf_matrix_' + str(est) + '.csv'\n","#convolution_mat.to_csv(savename, sep=';', decimal = '.')\n","\n","#sklearn.metrics.precision_recall_fscore_support\n","target_names = list()\n","for name in range(1,(labels.size)+1):\n","    target_names.append(str(name))\n","sum_mat = classification_report(y_v,X_v,target_names=target_names)\n","print(sum_mat)\n","print(sum_mat, file=open(results_txt, \"a\"))\n","\n","# Overall Accuracy (OAA)\n","print('OAA = {} %'.format(accuracy_score(y_v,X_v)*100))\n","print('OAA = {} %'.format(accuracy_score(y_v,X_v)*100), file=open(results_txt, \"a\"))"],"metadata":{"id":"ZnCjVATToB0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot confusion matrix\n","cm_val = confusion_matrix(roi_v[roi_v > 0],class_prediction[roi_v > 0])\n","plt.figure(figsize=(10,7))\n","sn.heatmap(cm_val, annot=True, fmt='g')\n","plt.xlabel('classes - predicted')\n","plt.ylabel('classes - truth')\n","plt.show()"],"metadata":{"id":"51ecWijAoM7c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Acknowledgements"],"metadata":{"id":"jwIRAh5Jod1E"}},{"cell_type":"markdown","source":["\n","\n","*   Chris Holden: http://ceholden.github.io/open-geo-tutorial/python/chapter_5_classification.html\n","*   Julien Rebetez https://github.com/terrai/rastercube/blob/master/rastercube/datasources/shputils.py\n","*   Precision, recall, f1-score: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n","\n","\n","\n"],"metadata":{"id":"Q061rVptok7_"}}]}